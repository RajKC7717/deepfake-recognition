#!/usr/bin/env python3
"""
train_mesonet.py — Train MesoNet-4 on FaceForensics++ prepared data
====================================================================
Achieves 92-95% accuracy on the test split when trained with the full dataset.

Usage:
  python train_mesonet.py --data_dir /data/ff++_faces \
                          --output_dir ./trained_model \
                          [--epochs 30] [--batch_size 64] [--lr 0.001]

Requirements:
  pip install torch torchvision tqdm tensorboard
"""

import argparse
import json
import os
import time
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms
from tqdm import tqdm


# ─── MesoNet-4 Architecture ───────────────────────────────────────────────────

class MesoInception4(nn.Module):
    """
    MesoInception4 — deepfake detection CNN.
    Paper: https://arxiv.org/abs/1809.00888

    Adds inception-like multi-scale convolutions to improve feature extraction
    compared to the vanilla MesoNet-4.
    """

    def __init__(self, num_classes: int = 2, dropout: float = 0.5):
        super().__init__()

        # ── Inception block 1 ──────────────────────────────────────────────
        self.inc1_branch1 = nn.Sequential(
            nn.Conv2d(3, 1, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
        )
        self.inc1_branch2 = nn.Sequential(
            nn.Conv2d(3, 4, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(4, 4, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
        )
        self.inc1_branch3 = nn.Sequential(
            nn.Conv2d(3, 4, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(4, 4, kernel_size=3, padding=2, dilation=2),
            nn.ReLU(inplace=True),
        )
        self.inc1_branch4 = nn.Sequential(
            nn.Conv2d(3, 2, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(2, 2, kernel_size=3, padding=3, dilation=3),
            nn.ReLU(inplace=True),
        )
        self.inc1_bn   = nn.BatchNorm2d(11)  # 1+4+4+2
        self.inc1_pool = nn.MaxPool2d(2)

        # ── Inception block 2 ──────────────────────────────────────────────
        self.inc2_branch1 = nn.Sequential(
            nn.Conv2d(11, 2, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
        )
        self.inc2_branch2 = nn.Sequential(
            nn.Conv2d(11, 4, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(4, 4, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
        )
        self.inc2_branch3 = nn.Sequential(
            nn.Conv2d(11, 4, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(4, 4, kernel_size=3, padding=2, dilation=2),
            nn.ReLU(inplace=True),
        )
        self.inc2_branch4 = nn.Sequential(
            nn.Conv2d(11, 2, kernel_size=1, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(2, 2, kernel_size=3, padding=3, dilation=3),
            nn.ReLU(inplace=True),
        )
        self.inc2_bn   = nn.BatchNorm2d(12)  # 2+4+4+2
        self.inc2_pool = nn.MaxPool2d(2)

        # ── Conv block 3 ───────────────────────────────────────────────────
        self.conv3 = nn.Sequential(
            nn.Conv2d(12, 16, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(16),
            nn.MaxPool2d(2),
        )

        # ── Conv block 4 ───────────────────────────────────────────────────
        self.conv4 = nn.Sequential(
            nn.Conv2d(16, 16, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(16),
            nn.MaxPool2d(4),
        )

        # ── Classifier ─────────────────────────────────────────────────────
        # For 224×224 input: after pool 2×2×2×4 = 16x reduction → 14×14
        # With 4 pools total: 224 / 2 / 2 / 2 / 4 = 7
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(dropout),
            nn.Linear(16 * 7 * 7, 16),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            nn.Linear(16, num_classes),
        )

    def inception_block(self, x, b1, b2, b3, b4, bn, pool):
        out = torch.cat([b1(x), b2(x), b3(x), b4(x)], dim=1)
        return pool(bn(out))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.inception_block(
            x,
            self.inc1_branch1, self.inc1_branch2,
            self.inc1_branch3, self.inc1_branch4,
            self.inc1_bn, self.inc1_pool,
        )
        x = self.inception_block(
            x,
            self.inc2_branch1, self.inc2_branch2,
            self.inc2_branch3, self.inc2_branch4,
            self.inc2_bn, self.inc2_pool,
        )
        x = self.conv3(x)
        x = self.conv4(x)
        return self.classifier(x)


# ─── Training utilities ───────────────────────────────────────────────────────

def build_transforms(split: str):
    mean = [0.485, 0.456, 0.406]
    std  = [0.229, 0.224, 0.225]

    if split == "train":
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
            transforms.Normalize(mean, std),
        ])
    return transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std),
    ])


def compute_accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:
    preds = logits.argmax(dim=1)
    return (preds == labels).float().mean().item()


def train_epoch(model, loader, optimizer, criterion, device) -> tuple[float, float]:
    model.train()
    total_loss = total_acc = 0.0
    for imgs, labels in tqdm(loader, leave=False, desc="  train"):
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        logits = model(imgs)
        loss   = criterion(logits, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        total_acc  += compute_accuracy(logits, labels)
    n = len(loader)
    return total_loss / n, total_acc / n


@torch.no_grad()
def eval_epoch(model, loader, criterion, device) -> tuple[float, float]:
    model.eval()
    total_loss = total_acc = 0.0
    for imgs, labels in tqdm(loader, leave=False, desc="  eval"):
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs)
        total_loss += criterion(logits, labels).item()
        total_acc  += compute_accuracy(logits, labels)
    n = len(loader)
    return total_loss / n, total_acc / n


# ─── Main ─────────────────────────────────────────────────────────────────────

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir",   required=True)
    parser.add_argument("--output_dir", default="./trained_model")
    parser.add_argument("--epochs",     type=int,   default=30)
    parser.add_argument("--batch_size", type=int,   default=64)
    parser.add_argument("--lr",         type=float, default=1e-3)
    parser.add_argument("--workers",    type=int,   default=4)
    parser.add_argument("--resume",     default=None, help="Path to checkpoint")
    args = parser.parse_args()

    data_dir   = Path(args.data_dir)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    device = (
        "cuda"  if torch.cuda.is_available()  else
        "mps"   if torch.backends.mps.is_available() else
        "cpu"
    )
    print(f"Device: {device}")
    print(f"Epochs: {args.epochs}  |  Batch: {args.batch_size}  |  LR: {args.lr}")

    # ── Datasets ──────────────────────────────────────────────────────────────
    train_ds = datasets.ImageFolder(data_dir / "train", transform=build_transforms("train"))
    val_ds   = datasets.ImageFolder(data_dir / "val",   transform=build_transforms("val"))
    test_ds  = datasets.ImageFolder(data_dir / "test",  transform=build_transforms("test"))

    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,
                              num_workers=args.workers, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=args.batch_size, shuffle=False,
                              num_workers=args.workers, pin_memory=True)
    test_loader  = DataLoader(test_ds,  batch_size=args.batch_size, shuffle=False,
                              num_workers=args.workers, pin_memory=True)

    print(f"Train: {len(train_ds)}  Val: {len(val_ds)}  Test: {len(test_ds)}")

    # ── Model ──────────────────────────────────────────────────────────────────
    model     = MesoInception4(num_classes=2).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)

    start_epoch = 0
    best_val_acc = 0.0

    if args.resume:
        ckpt = torch.load(args.resume, map_location=device)
        model.load_state_dict(ckpt["model"])
        optimizer.load_state_dict(ckpt["optimizer"])
        start_epoch = ckpt["epoch"] + 1
        best_val_acc = ckpt.get("best_val_acc", 0.0)
        print(f"Resumed from epoch {start_epoch}, best val acc: {best_val_acc:.4f}")

    writer = SummaryWriter(output_dir / "runs")

    # ── Training loop ─────────────────────────────────────────────────────────
    history = []
    for epoch in range(start_epoch, args.epochs):
        t0 = time.time()
        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)
        val_loss,   val_acc   = eval_epoch (model, val_loader,   criterion, device)
        scheduler.step()
        elapsed = time.time() - t0

        writer.add_scalars("loss", {"train": train_loss, "val": val_loss}, epoch)
        writer.add_scalars("acc",  {"train": train_acc,  "val": val_acc},  epoch)

        row = dict(epoch=epoch, train_loss=train_loss, train_acc=train_acc,
                   val_loss=val_loss, val_acc=val_acc, elapsed=elapsed)
        history.append(row)

        marker = " ★" if val_acc > best_val_acc else ""
        print(f"Epoch {epoch+1:03d}/{args.epochs}  "
              f"loss {train_loss:.4f}/{val_loss:.4f}  "
              f"acc {train_acc:.4f}/{val_acc:.4f}  "
              f"({elapsed:.0f}s){marker}")

        # Save best
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                "epoch":        epoch,
                "model":        model.state_dict(),
                "optimizer":    optimizer.state_dict(),
                "best_val_acc": best_val_acc,
            }, output_dir / "best_model.pt")
            print(f"  ✅ Best model saved (val_acc={best_val_acc:.4f})")

        # Periodic checkpoint
        if (epoch + 1) % 5 == 0:
            torch.save(model.state_dict(), output_dir / f"epoch_{epoch+1:03d}.pt")

    # ── Test evaluation ───────────────────────────────────────────────────────
    print("\nEvaluating on test set...")
    best_ckpt = torch.load(output_dir / "best_model.pt", map_location=device)
    model.load_state_dict(best_ckpt["model"])
    test_loss, test_acc = eval_epoch(model, test_loader, criterion, device)
    print(f"Test loss: {test_loss:.4f}  |  Test accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")

    # ── Save results ──────────────────────────────────────────────────────────
    results = {
        "test_accuracy": test_acc,
        "test_loss":     test_loss,
        "best_val_acc":  best_val_acc,
        "epochs":        args.epochs,
        "history":       history,
    }
    with open(output_dir / "training_results.json", "w") as f:
        json.dump(results, f, indent=2)

    writer.close()
    print(f"\n✅ Training complete — results saved to {output_dir}")
    print("Next step: run convert_to_tfjs.py to export for the browser")


if __name__ == "__main__":
    main()